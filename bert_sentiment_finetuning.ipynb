{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7859d40-3a1e-4862-bb7a-f7090daa1820",
   "metadata": {},
   "source": [
    "## Comparision of BERT pre-trained model for sentiment analysis with and without finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b48b55-9779-4971-8eb9-bf3d7380f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, BertTokenizer,BertModel,BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a299020f-f339-4cf3-a4e3-3cf7478bd410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "sentiment_classifier = pipeline(task='text-classification',model=model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f1a217-a47d-4b8f-9339-f556fa2bfea3",
   "metadata": {},
   "source": [
    "##### using pretrained model on clear postive and negative sentiment statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469ce65a-0a37-4c43-a1bb-af407ecf7520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.45943698287010193}]\n",
      "[{'label': 'LABEL_1', 'score': 0.47597670555114746}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_classifier(\"This is worst movie\"))\n",
    "print(sentiment_classifier(\"This is very good movie\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e39e06-49a5-4737-bc10-e8dd90f3b67a",
   "metadata": {},
   "source": [
    "##### even for very clear sentiments, we can see very low scores and both still belong to same classification as per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d599c58-2883-4545-a0eb-4320c5d63e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qq datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86227ac1-b23b-490a-a37f-26f0e25e624e",
   "metadata": {},
   "source": [
    "##### Will use imbd reviews dataset to finetune the model for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2fc3fe-3e5c-4c92-ab13-ba94be1e6613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b75e5c93-db9e-45da-a086-c250e40331a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87455ab0-86ba-4601-870e-45990fc0f800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce512420-315c-4aa7-8da7-f3e54bfb31e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({\"text\":dataset[\"train\"][\"text\"],\"label\":dataset[\"train\"][\"label\"]}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcf03e0-bc08-4de9-b61a-1950363fcab4",
   "metadata": {},
   "source": [
    "###### label 0 for negative sentiment\n",
    "###### label 1 for positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e95080d0-1fc8-4bfd-9494-e226cb4bc75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"this is to test tokenization\",\"This is another example. Bit lengthy than before one\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c62c2a83-f159-4a8d-ac6f-1aacc265ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_out = tokenizer(sentences,padding=True,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fc17436-454a-477e-9bbd-82930f8b2fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2023, 2003, 2000, 3231, 19204, 3989, 102, 0, 0, 0, 0], [101, 2023, 2003, 2178, 2742, 1012, 2978, 12401, 2084, 2077, 2028, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd360c-8ecf-438e-b8c0-1aa286c0c533",
   "metadata": {},
   "source": [
    "##### sample of tokenized output on two inputs, \n",
    "##### fields in output are\n",
    "##### input_ids = > each corresponding to token of input\n",
    "##### token_type_ids => varies if case seperator occurs in input\n",
    "##### attention_mask => specifies data which model should attend/consider, in case of varying lenghts, with padding enables, makes all input tokens of same length with added paddings, where padded is masked as 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7ec8691-1d6f-48ef-9fba-63308dff819a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] this is another example. bit lengthy than before one [SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_out[\"input_ids\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb8b0e10-3bf8-4ff4-8fbf-2dce0d6ef384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] this is to test tokenization [SEP] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_out[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10567d1c-1f2c-4bdf-aa91-a2323cca3a86",
   "metadata": {},
   "source": [
    "function to get process dataset to create above fields in original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88a523a1-f758-4ddb-a0a7-0104e0700db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0738c967-e008-42ef-91fb-a8a3237180a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6896fc54-5b1b-4f1e-b24f-910b3bc75475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7682bb0-bef2-4b65-b267-ab39498685d0",
   "metadata": {},
   "source": [
    "##### Preparing for training/finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "716d5128-7b8f-433b-bda0-fb5fed9856dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer,TrainingArguments,DataCollatorForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ef150ae-6ce1-4a31-902e-7b37515d5022",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\"test-classifier\",\n",
    "                         eval_strategy='epoch',\n",
    "                         learning_rate=2e-5,\n",
    "                         per_device_train_batch_size=16,\n",
    "                         per_device_eval_batch_size=16,\n",
    "                         num_train_epochs=3,\n",
    "                         weight_decay=0.01,\n",
    "                        )\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b5590d5-4463-47f3-a311-c41630edc580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qq evaluate\n",
    "# !pip install -qq seqeval\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import numpy as np\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73489123-9455-4d03-85b1-44ada7d59871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reduce training resources/time, selcting randomly sampled dataset\n",
    "small_train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_dataset[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be7d521f-bcd0-4b94-a784-0420639b5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b09096b1-355b-49f1-ba30-42641b8bfa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d83162-b103-4b25-8218-8c19be1f7457",
   "metadata": {},
   "source": [
    "#### Using the finetune model specifing the path of above configured directory (test-classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dd7910b-fb49-48f9-8165-37cde7404e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('test-classifier/checkpoint-189')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed4147b6-4d49-44cb-8703-f67477a126f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classifier = pipeline(task='text-classification',model=model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fe5bbc6-d27a-4ba0-add6-80283ef80f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.8362260460853577}]\n",
      "[{'label': 'LABEL_1', 'score': 0.8860337734222412}]\n",
      "[{'label': 'LABEL_1', 'score': 0.8876245617866516}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_classifier(\"This is worst movie\"))\n",
    "print(sentiment_classifier('This is movie is worth watchiing.'))\n",
    "print(sentiment_classifier('This movie of that level where i get to sleep immediately'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47af83-f7d2-4915-a110-34b6e931a70b",
   "metadata": {},
   "source": [
    "#### Now that model is able to classify clear negative(label 0) and positive(label 1) statement with clear scores.\n",
    "#### But sarcastic statement is still mixing up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f2501-96e8-4a8b-bf7d-3fa3b42b4b9b",
   "metadata": {},
   "source": [
    "#### Will retrain model with few more data with addtional set with sarcastice reviews/statements as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "733cc7d0-07ab-48ca-b639-5caf8513c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qq openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5e56176-7d52-41ac-aefd-266f4f8584ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sarcastic_df = pd.read_excel('sarcastic_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50f46e0d-e050-46af-a9d2-3f3ce0b1b595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08fa449558c4921b172ea89f7a4274f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "sarcastic_df = Dataset.from_pandas(sarcastic_df)\n",
    "sarcastic_tokenized = sarcastic_df.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "376b0add-4ddb-4109-9e68-15f93f4deeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 60\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcastic_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c434bdb9-0fab-43ba-ae9b-c6e46b357cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_train_dataset = sarcastic_tokenized.shuffle(seed=42).train_test_split(test_size=0.2,seed=42)[\"train\"]\n",
    "tiny_eval_dataset = sarcastic_tokenized.shuffle(seed=42).train_test_split(test_size=0.2,seed=42)[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2651d14-6f57-4b7a-9316-3a108d129a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 48\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcastic_tokenized.shuffle(seed=42).train_test_split(test_size=0.2,seed=42)[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f50059e9-c071-4a3f-b4c6-1128e970ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer,TrainingArguments,DataCollatorForTokenClassification\n",
    "args = TrainingArguments(\"sarcastic-classifier\",\n",
    "                         eval_strategy='epoch',\n",
    "                         learning_rate=2e-5,\n",
    "                         per_device_train_batch_size=16,\n",
    "                         per_device_eval_batch_size=16,\n",
    "                         num_train_epochs=3,\n",
    "                         weight_decay=0.01,\n",
    "                        )\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tiny_train_dataset,\n",
    "    eval_dataset=tiny_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f70926d8-6d86-4ba0-9257-146259267aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c15fc2c-be9b-4ba5-9b39-5f85e99bbf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrained_model = BertForSequenceClassification.from_pretrained('sarcastic-classifier/checkpoint-9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9380db24-5910-4e4d-9d59-dc7b0b6e2ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classifier = pipeline(task='text-classification',model=retrained_model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24190dc6-abf5-4103-a26a-02d0ae1448af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.8150907158851624}]\n",
      "[{'label': 'LABEL_1', 'score': 0.5845213532447815}]\n",
      "[{'label': 'LABEL_0', 'score': 0.7711818218231201}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_classifier(\"This is worst movie\"))\n",
    "print(sentiment_classifier('This is movie is worth watchiing.'))\n",
    "print(sentiment_classifier('This movie of that level where i get to sleep immediately'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a31a83-fda2-4bf6-9bbe-8bc2f68679eb",
   "metadata": {},
   "source": [
    "#### now with more finetuning, i can see model is able to detect/classify sarcastic statement aswell and also score of sceond statement is reduced as per it's sentiment indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d19d16-a315-4227-82d8-03137c66be90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
